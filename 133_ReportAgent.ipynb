{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suajder/agent/blob/main/133_ReportAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7160ed2",
      "metadata": {
        "id": "e7160ed2"
      },
      "source": [
        "<div style=\"background-color:#000;\"><img src=\"https://github.com/pyquantnews/PyQuantNewsletter/blob/main/pqn.png?raw=1\"></img></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "749e45db",
      "metadata": {
        "id": "749e45db",
        "outputId": "f46e875b-d313-49f7-8f26-d259cd498b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-99c7724365dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from llama_index.core.agent.workflow import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mFunctionAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.workflow import Context\n",
        "from llama_index.core.agent.workflow import (\n",
        "    FunctionAgent,\n",
        "    ReActAgent,\n",
        "    AgentWorkflow,\n",
        "    AgentInput,\n",
        "    AgentOutput,\n",
        "    ToolCall,\n",
        "    ToolCallResult,\n",
        "    AgentStream,\n",
        ")\n",
        "from tavily import AsyncTavilyClient\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "a84F7K6M39GG",
        "outputId": "25dd8ccb-2b35-494c-9e53-f09fbebf7d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "a84F7K6M39GG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.61.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.11.11)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.11-py3-none-any.whl.metadata (912 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Collecting certifi<2025.0.0,>=2024.7.4 (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.14.0)\n",
            "Collecting llama-cloud-services (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n",
            "Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.4-py3-none-any.whl (39 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.11-py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.0-py3-none-any.whl (4.8 kB)\n",
            "Downloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading llama_cloud_services-0.6.0-py3-none-any.whl (22 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, certifi, typing-inspect, tiktoken, dataclasses-json, llama-index-core, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "Successfully installed certifi-2024.12.14 dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.11 llama-cloud-services-0.6.0 llama-index-0.12.16 llama-index-agent-openai-0.4.3 llama-index-cli-0.4.0 llama-index-core-0.12.16.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.18 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.4 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.0 marshmallow-3.26.1 mypy-extensions-1.0.0 pypdf-5.2.0 python-dotenv-1.0.1 striprtf-0.0.26 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "a04d8428cb9f41348d637094296258e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7c7d7f",
      "metadata": {
        "id": "0d7c7d7f"
      },
      "source": [
        "## Create a function to perform web searches asynchronously"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac3437e",
      "metadata": {
        "id": "4ac3437e"
      },
      "source": [
        "We set up an asynchronous function to perform web searches using the Tavily API. This function will take a query string as input and return search results. It uses an API key from environment variables for authentication. The results are converted to a string format before being returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2da547",
      "metadata": {
        "id": "2d2da547"
      },
      "outputs": [],
      "source": [
        "async def search_web(query: str) -> str:\n",
        "    client = AsyncTavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
        "    return str(await client.search(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37589108",
      "metadata": {
        "id": "37589108"
      },
      "source": [
        "The function is designed to be asynchronous, allowing other tasks to run while waiting for the search results. It initializes an asynchronous client by using the API key stored in the environment variables, ensuring secure access. The search results are awaited, meaning the function will pause until the results are ready. The results are then converted to a string to ensure compatibility with other parts of the program."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d47fab0",
      "metadata": {
        "id": "2d47fab0"
      },
      "source": [
        "## Implement functions to record, write, and review notes and reports"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8da272",
      "metadata": {
        "id": "1b8da272"
      },
      "source": [
        "We define several asynchronous functions to record notes, write reports, and review them. Each function interacts with a context object to store and retrieve the current state. These functions update the state with relevant data, such as notes or report content, and return confirmation messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b78aa81",
      "metadata": {
        "id": "6b78aa81"
      },
      "outputs": [],
      "source": [
        "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
        "    current_state = await ctx.get(\"state\")\n",
        "    if \"research_notes\" not in current_state:\n",
        "        current_state[\"research_notes\"] = {}\n",
        "    current_state[\"research_notes\"][notes_title] = notes\n",
        "    await ctx.set(\"state\", current_state)\n",
        "    return \"Notes recorded.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6376dbf6",
      "metadata": {
        "id": "6376dbf6"
      },
      "outputs": [],
      "source": [
        "async def write_report(ctx: Context, report_content: str) -> str:\n",
        "    current_state = await ctx.get(\"state\")\n",
        "    current_state[\"report_content\"] = report_content\n",
        "    await ctx.set(\"state\", current_state)\n",
        "    return \"Report written.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ac7efa",
      "metadata": {
        "id": "89ac7efa"
      },
      "outputs": [],
      "source": [
        "async def review_report(ctx: Context, review: str) -> str:\n",
        "    current_state = await ctx.get(\"state\")\n",
        "    current_state[\"review\"] = review\n",
        "    await ctx.set(\"state\", current_state)\n",
        "    return \"Report reviewed.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899a176f",
      "metadata": {
        "id": "899a176f"
      },
      "source": [
        "These functions perform different tasks related to managing information. The `record_notes` function checks if research notes exist in the current state and adds them if not. It then updates the notes with the provided title and content. The `write_report` function saves the report content to the state, while the `review_report` function saves feedback on the report. The context object ensures that the state is maintained consistently across different parts of the program."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a6cc22d",
      "metadata": {
        "id": "6a6cc22d"
      },
      "source": [
        "## Define agents to handle specific tasks in the workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dec3c55",
      "metadata": {
        "id": "8dec3c55"
      },
      "source": [
        "We create three different agents: ResearchAgent, WriteAgent, and ReviewAgent. Each agent has a specific purpose and is equipped with a set of functions it can use. The agents can hand off control to each other when needed to complete the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5497424d",
      "metadata": {
        "id": "5497424d"
      },
      "outputs": [],
      "source": [
        "research_agent = FunctionAgent(\n",
        "    name=\"ResearchAgent\",\n",
        "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
        "    system_prompt=(\n",
        "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
        "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic. \"\n",
        "        \"You should have at least some notes on a topic before handing off control to the WriteAgent.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    tools=[search_web, record_notes],\n",
        "    can_handoff_to=[\"WriteAgent\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f521ba38",
      "metadata": {
        "id": "f521ba38"
      },
      "outputs": [],
      "source": [
        "write_agent = FunctionAgent(\n",
        "    name=\"WriteAgent\",\n",
        "    description=\"Useful for writing a report on a given topic.\",\n",
        "    system_prompt=(\n",
        "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
        "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
        "        \"Once the report is written, you should get feedback at least once from the ReviewAgent.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    tools=[write_report],\n",
        "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d86f5790",
      "metadata": {
        "id": "d86f5790"
      },
      "outputs": [],
      "source": [
        "review_agent = FunctionAgent(\n",
        "    name=\"ReviewAgent\",\n",
        "    description=\"Useful for reviewing a report and providing feedback.\",\n",
        "    system_prompt=(\n",
        "        \"You are the ReviewAgent that can review the write report and provide feedback. \"\n",
        "        \"Your review should either approve the current report or request changes for the WriteAgent to implement. \"\n",
        "        \"If you have feedback that requires changes, you should hand off control to the WriteAgent to implement the changes after submitting the review.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    tools=[review_report],\n",
        "    can_handoff_to=[\"WriteAgent\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6daafb0",
      "metadata": {
        "id": "e6daafb0"
      },
      "source": [
        "Each agent has a specific role to play in the workflow. The ResearchAgent is responsible for gathering information and recording notes. Once sufficient notes are gathered, it hands off control to the WriteAgent. The WriteAgent takes these notes and composes a report in markdown format. After writing, it seeks feedback from the ReviewAgent. The ReviewAgent evaluates the report, providing approval or suggesting changes. This structured approach ensures that tasks are completed efficiently and accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98cb9906",
      "metadata": {
        "id": "98cb9906"
      },
      "source": [
        "## Set up and execute the workflow using the defined agents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c24817e",
      "metadata": {
        "id": "5c24817e"
      },
      "source": [
        "We set up an AgentWorkflow to organize the sequence of actions performed by the agents. The workflow starts with the ResearchAgent and maintains a state to track progress. We then run the workflow with a user message, simulating a task request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3159708",
      "metadata": {
        "id": "f3159708"
      },
      "outputs": [],
      "source": [
        "agent_workflow = AgentWorkflow(\n",
        "    agents=[research_agent, write_agent, review_agent],\n",
        "    root_agent=research_agent.name,\n",
        "    initial_state={\n",
        "        \"research_notes\": {},\n",
        "        \"report_content\": \"Not written yet.\",\n",
        "        \"review\": \"Review required.\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69c7528",
      "metadata": {
        "id": "c69c7528"
      },
      "outputs": [],
      "source": [
        "handler = agent_workflow.run(\n",
        "    user_msg=(\n",
        "        \"Write me a report on why the announcement of the Deepseek R1 large language model rattled investors in Nvidia. \"\n",
        "        \"Briefly describe what Deepseek R1 is, why it made news globally, and why Nvidia's stock price tanked. \"\n",
        "    )\n",
        ")\n",
        "\n",
        "current_agent = None\n",
        "current_tool_calls = \"\"\n",
        "async for event in handler.stream_events():\n",
        "    if (\n",
        "        hasattr(event, \"current_agent_name\")\n",
        "        and event.current_agent_name != current_agent\n",
        "    ):\n",
        "        current_agent = event.current_agent_name\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"ü§ñ Agent: {current_agent}\")\n",
        "        print(f\"{'='*50}\\n\")\n",
        "    elif isinstance(event, AgentOutput):\n",
        "        if event.response.content:\n",
        "            print(\"üì§ Output:\", event.response.content)\n",
        "        if event.tool_calls:\n",
        "            print(\n",
        "                \"üõ†Ô∏è  Planning to use tools:\",\n",
        "                [call.tool_name for call in event.tool_calls],\n",
        "            )\n",
        "    elif isinstance(event, ToolCallResult):\n",
        "        print(f\"üîß Tool Result ({event.tool_name}):\")\n",
        "        print(f\"  Arguments: {event.tool_kwargs}\")\n",
        "        print(f\"  Output: {event.tool_output}\")\n",
        "    elif isinstance(event, ToolCall):\n",
        "        print(f\"üî® Calling Tool: {event.tool_name}\")\n",
        "        print(f\"  With arguments: {event.tool_kwargs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1178ac",
      "metadata": {
        "id": "ac1178ac"
      },
      "source": [
        "The workflow is initialized with a list of agents and their respective roles. The ResearchAgent is set as the starting point, guiding the initial data gathering. The initial state is defined to track the progress of notes, report content, and review status. The workflow is executed by running it with a user message, which simulates a request to perform a specific task. This setup ensures that the agents collaborate smoothly, following a structured sequence to achieve the desired outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa16ac5",
      "metadata": {
        "id": "1fa16ac5"
      },
      "source": [
        "## Your next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2569ef-48ea-41d2-b682-11e48976b3ec",
      "metadata": {
        "id": "8b2569ef-48ea-41d2-b682-11e48976b3ec"
      },
      "source": [
        "Try modifying the code to explore different functionalities. You might change the user message to request a report on a different topic. Alternatively, consider integrating additional tools for the agents to use. This will help you understand the flexibility and potential of the agent-based workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8328b12a",
      "metadata": {
        "id": "8328b12a"
      },
      "source": [
        "<a href=\"https://pyquantnews.com/\">PyQuant News</a> is where finance practitioners level up with Python for quant finance, algorithmic trading, and market data analysis. Looking to get started? Check out the fastest growing, top-selling course to <a href=\"https://gettingstartedwithpythonforquantfinance.com/\">get started with Python for quant finance</a>. For educational purposes. Not investment advise. Use at your own risk."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}